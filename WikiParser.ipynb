{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\" color=\"#666699\">Natural Language Analytics</font>\n",
    "<br>\n",
    "<br>\n",
    "<font size=\"5\" color=\"#9370DB\">Excersise 1</font>\n",
    "<br>\n",
    "<br>\n",
    "<font size=\"4\" color=\"#666699\">Author: </font><font size=\"4\" color=\"#A8A8A8\">Angeliki Mylonaki</font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Extracting Text fr</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting text from:  https://en.wikipedia.org/wiki/Artificial_neural_network\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import  wikipedia\n",
    "\n",
    "#export to cvs-Excvel\n",
    "#https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe\n",
    "\n",
    "#Getting context of website using Wikipedia API\n",
    "p= wikipedia.page(\"Artificial neural network\")\n",
    "\n",
    "print \"Getting text from: \", p.url\n",
    "text=p.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Word count and Vocabulary</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<title> Word Count and Vocabulary</title>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary:  2495 words.\n",
      "\n",
      "Vocabulary contains: \n",
      "***********\n",
      "limited\n",
      "biophysical\n",
      "similarity\n",
      "desirable\n",
      "catch\n",
      "circuitry\n",
      "entropy\n",
      "consists\n",
      "Van\n",
      "CMOS\n",
      "forget\n",
      "whose\n",
      "calculate\n",
      "investigation\n",
      "under\n",
      "worth\n",
      "updated\n",
      "risk\n",
      "downstream\n",
      "dynamic\n",
      "activation\n",
      "rise\n",
      "updates\n",
      "classifications\n",
      "convexity\n",
      "look\n",
      "basics\n",
      "transduce\n",
      "Pitts\n",
      "vector\n",
      "Go\n",
      "sleep\n",
      "1940s\n",
      "commented\n",
      "specially\n",
      "disciplines\n",
      "estimates\n",
      "empirical\n",
      "approximation\n",
      "second\n",
      "estimated\n",
      "machines\n",
      "even\n",
      "employ\n",
      "errors\n",
      "Initially\n",
      "selected\n",
      "Clarendon\n",
      "reconstruction\n",
      "resilient\n",
      "new\n",
      "net\n",
      "poorly\n",
      "million\n",
      "simultaneously\n",
      "behavior\n",
      "Foundation\n",
      "here\n",
      "reported\n",
      "represented\n",
      "digits\n",
      "property\n",
      "items\n",
      "k\n",
      "changed\n",
      "pooling\n",
      "Choosing\n",
      "permit\n",
      "calculators\n",
      "pendeteksi\n",
      "suitable\n",
      "changes\n",
      "Neuromorphic\n",
      "criticism\n",
      "appropriately\n",
      "offs\n",
      "Group\n",
      "projection\n",
      "classification\n",
      "Support\n",
      "highly\n",
      "neutrons\n",
      "visible\n",
      "specifics\n",
      "CTC\n",
      "total\n",
      "unit\n",
      "experimentation\n",
      "8716324\n",
      "would\n",
      "Introduction\n",
      "therefore\n",
      "spike\n",
      "type\n",
      "until\n",
      "drawbacks\n",
      "successful\n",
      "interaction\n",
      "V\n",
      "m_\n",
      "94\n",
      "must\n",
      "1991\n",
      "1993\n",
      "1992\n",
      "word\n",
      "1994\n",
      "1997\n",
      "Habit\n",
      "1999\n",
      "work\n",
      "Alternatives\n",
      "itself\n",
      "concepts\n",
      "backpropagated\n",
      "example\n",
      "stagnated\n",
      "indicated\n",
      "iterative\n",
      "unreadable\n",
      "organized\n",
      "discovery\n",
      "implementations\n",
      "Brian\n",
      "21522159\n",
      "mail\n",
      "McClelland\n",
      "guarantee\n",
      "end\n",
      "hoc\n",
      "provide\n",
      "travel\n",
      "feature\n",
      "discriminatively\n",
      "machine\n",
      "very\n",
      "adjacent\n",
      "significance\n",
      "L_\n",
      "9780471108061\n",
      "A\n",
      "poker\n",
      "abstraction\n",
      "turing\n",
      "after\n",
      "minimized\n",
      "lab\n",
      "L2\n",
      "curiosity\n",
      "retain\n",
      "minimizes\n",
      "Petersen\n",
      "parallel\n",
      "types\n",
      "Jeanette\n",
      "All\n",
      "third\n",
      "complexity\n",
      "algorithms\n",
      "Another\n",
      "correlation\n",
      "ICDAR\n",
      "1000\n",
      "order\n",
      "recurrent\n",
      "fetus\n",
      "feedback\n",
      "over\n",
      "nets\n",
      "before\n",
      "Addison\n",
      "directional\n",
      "trying\n",
      "Here\n",
      "writing\n",
      "better\n",
      "vast\n",
      "hidden\n",
      "easier\n",
      "overcome\n",
      "then\n",
      "them\n",
      "copying\n",
      "combination\n",
      "Analysis\n",
      "break\n",
      "Merck\n",
      "they\n",
      "2301\n",
      "one\n",
      "Rumelhart\n",
      "structural\n",
      "Control\n",
      "represents\n",
      "Klawonn\n",
      "DBM\n",
      "prostheses\n",
      "DBN\n",
      "reasonably\n",
      "l\n",
      "emphatic\n",
      "each\n",
      "Hebbian\n",
      "classifier\n",
      "associative\n",
      "mean\n",
      "Developmental\n",
      "financial\n",
      "evolve\n",
      "weightless\n",
      "principles\n",
      "solution\n",
      "trading\n",
      "reached\n",
      "extract\n",
      "backgammon\n",
      "network\n",
      "gradient\n",
      "restricted\n",
      "content\n",
      "adapt\n",
      "0198538499\n",
      "Hubel\n",
      "medicine\n",
      "millions\n",
      "foundation\n",
      "numerical\n",
      "linear\n",
      "written\n",
      "3203\n",
      "University\n",
      "free\n",
      "standard\n",
      "W\n",
      "mastering\n",
      "estimate\n",
      "Criticism\n",
      "enormous\n",
      "Cambridge\n",
      "recovering\n",
      "created\n",
      "starts\n",
      "National\n",
      "2279\n",
      "days\n",
      "MIT\n",
      "incorporated\n",
      "Eduardo\n",
      "mathbb\n",
      "Tsitsiklis\n",
      "features\n",
      "coding\n",
      "primary\n",
      "rank\n",
      "synthesize\n",
      "relations\n",
      "another\n",
      "37875698\n",
      "top\n",
      "needed\n",
      "observations\n",
      "Press\n",
      "ranging\n",
      "Alexander\n",
      "B\n",
      "rectifier\n",
      "serve\n",
      "rectified\n",
      "837524179\n",
      "somewhat\n",
      "peculiar\n",
      "begins\n",
      "target\n",
      "showed\n",
      "connectionist\n",
      "approximations\n",
      "scenes\n",
      "connectionism\n",
      "See\n",
      "classes\n",
      "enables\n",
      "ldots\n",
      "Unit\n",
      "extracting\n",
      "mini\n",
      "29877717\n",
      "fashion\n",
      "modern\n",
      "mind\n",
      "talking\n",
      "manner\n",
      "emphasizing\n",
      "Instead\n",
      "ocean\n",
      "Williams\n",
      "relatively\n",
      "Then\n",
      "strength\n",
      "Christian\n",
      "1969\n",
      "1965\n",
      "latter\n",
      "cope\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "overtook\n",
      "chess\n",
      "They\n",
      "transmit\n",
      "Gallery\n",
      "though\n",
      "Weng\n",
      "object\n",
      "anatomy\n",
      "optimized\n",
      "deepESNs\n",
      "phase\n",
      "Biological\n",
      "mitigate\n",
      "QR\n",
      "observation\n",
      "medical\n",
      "flow\n",
      "QA\n",
      "GMDH\n",
      "principle\n",
      "Its\n",
      "incomplete\n",
      "0201515601\n",
      "random\n",
      "solutions\n",
      "Powell\n",
      "latent\n",
      "just\n",
      "spite\n",
      "shuffling\n",
      "implementation\n",
      "situations\n",
      "delays\n",
      "integrate\n",
      "predecessor\n",
      "infty\n",
      "mixture\n",
      "above\n",
      "wide\n",
      "de\n",
      "despite\n",
      "X\n",
      "Papert\n",
      "runs\n",
      "covering\n",
      "GRBMs\n",
      "d_\n",
      "bad\n",
      "architecture\n",
      "analytical\n",
      "clean\n",
      "automatic\n",
      "pada\n",
      "electrodes\n",
      "Spike\n",
      "emergent\n",
      "observed\n",
      "depends\n",
      "result\n",
      "Android\n",
      "incorporating\n",
      "subject\n",
      "00\n",
      "01\n",
      "capacity\n",
      "tensor\n",
      "Egmont\n",
      "away\n",
      "artificial\n",
      "Choice\n",
      "symmetric\n",
      "score\n",
      "simplest\n",
      "drawn\n",
      "perceptrons\n",
      "tolerance\n",
      "Advanced\n",
      "handwritten\n",
      "we\n",
      "terms\n",
      "laureates\n",
      "Kopplung\n",
      "modeling\n",
      "rows\n",
      "MacKay\n",
      "improve\n",
      "essentially\n",
      "biologically\n",
      "against\n",
      "layered\n",
      "games\n",
      "Dreyfus\n",
      "receives\n",
      "faces\n",
      "w_\n",
      "variance\n",
      "pre\n",
      "Given\n",
      "sigmoidal\n",
      "connection\n",
      "recursive\n",
      "Schmidhuber\n",
      "pregnancy\n",
      "Prentice\n",
      "Method\n",
      "three\n",
      "been\n",
      "impeding\n",
      "replicate\n",
      "interest\n",
      "basic\n",
      "expected\n",
      "superhuman\n",
      "KPCA\n",
      "obtained\n",
      "graphical\n",
      "deeper\n",
      "drugs\n",
      "quantities\n",
      "Rprop\n",
      "worked\n",
      "applied\n",
      "n\n",
      "aim\n",
      "aid\n",
      "voice\n",
      "0442013108\n",
      "procedure\n",
      "manipulators\n",
      "is\n",
      "it\n",
      "ij\n",
      "counterexamples\n",
      "in\n",
      "comparative\n",
      "if\n",
      "containing\n",
      "descent\n",
      "credit\n",
      "perform\n",
      "make\n",
      "cumulative\n",
      "geoscience\n",
      "writer\n",
      "complex\n",
      "potentially\n",
      "split\n",
      "evaluate\n",
      "several\n",
      "grows\n",
      "independent\n",
      "Springer\n",
      "Dirichlet\n",
      "published\n",
      "hand\n",
      "potentials\n",
      "Y\n",
      "tune\n",
      "weakly\n",
      "maximizing\n",
      "1975\n",
      "1974\n",
      "1973\n",
      "1970\n",
      "incapable\n",
      "simulated\n",
      "the\n",
      "paradigm\n",
      "left\n",
      "proposed\n",
      "sentence\n",
      "photo\n",
      "mid\n",
      "assigned\n",
      "identify\n",
      "transforms\n",
      "human\n",
      "tilde\n",
      "Hebb\n",
      "32\n",
      "succeeding\n",
      "previous\n",
      "visualization\n",
      "S0031\n",
      "candidate\n",
      "instance\n",
      "had\n",
      "transformed\n",
      "board\n",
      "easy\n",
      "Philip\n",
      "has\n",
      "hat\n",
      "Apart\n",
      "D\n",
      "advances\n",
      "possible\n",
      "Algorithms\n",
      "possibly\n",
      "boxes\n",
      "depicts\n",
      "Rudolf\n",
      "cognitive\n",
      "performing\n",
      "Echo\n",
      "specific\n",
      "informative\n",
      "DeepDream\n",
      "steps\n",
      "sparse\n",
      "71770\n",
      "Further\n",
      "security\n",
      "Warren\n",
      "right\n",
      "deal\n",
      "plausible\n",
      "successfully\n",
      "Application\n",
      "Much\n",
      "Between\n",
      "HB\n",
      "altered\n",
      "contests\n",
      "HD\n",
      "embodied\n",
      "for\n",
      "bottom\n",
      "Ho\n",
      "embodies\n",
      "neuroscientists\n",
      "minimization\n",
      "predicting\n",
      "constructive\n",
      "Propagation\n",
      "noised\n",
      "Fahlman\n",
      "super\n",
      "properties\n",
      "takes\n",
      "zur\n",
      "limitation\n",
      "Image\n",
      "months\n",
      "o\n",
      "probabilities\n",
      "connected\n",
      "Machines\n",
      "nerve\n",
      "Use\n",
      "presence\n",
      "Hybrid\n",
      "two\n",
      "down\n",
      "coastal\n",
      "reducing\n",
      "often\n",
      "art\n",
      "amidst\n",
      "compression\n",
      "Kohonen\n",
      "topologies\n",
      "support\n",
      "initial\n",
      "approximate\n",
      "9781447150121\n",
      "Approaches\n",
      "way\n",
      "was\n",
      "ISIJ\n",
      "synthesis\n",
      "lowest\n",
      "decoded\n",
      "σ\n",
      "Stacked\n",
      "automate\n",
      "form\n",
      "forming\n",
      "becoming\n",
      "DNN\n",
      "encoder\n",
      "decoder\n",
      "encoded\n",
      "Z\n",
      "true\n",
      "Kruse\n",
      "trains\n",
      "ancestral\n",
      "devices\n",
      "cancers\n",
      "DNs\n",
      "accelerate\n",
      "diagnose\n",
      "computing\n",
      "Parallelization\n",
      "abstract\n",
      "statistic\n",
      "proven\n",
      "Potential\n",
      "exist\n",
      "n_\n",
      "distributions\n",
      "check\n",
      "Shanno\n",
      "uncorrupt\n",
      "no\n",
      "whereas\n",
      "when\n",
      "topped\n",
      "interested\n",
      "role\n",
      "digital\n",
      "shrink\n",
      "node\n",
      "E\n",
      "models\n",
      "preceding\n",
      "update\n",
      "variable\n",
      "neuroscience\n",
      "hashing\n",
      "faster\n",
      "sigma\n",
      "interval\n",
      "modules\n",
      "together\n",
      "time\n",
      "push\n",
      "Kelley\n",
      "stacks\n",
      "250p\n",
      "neighbors\n",
      "concept\n",
      "chain\n",
      "particular\n",
      "Systeme\n",
      "computation\n",
      "skin\n",
      "displaying\n",
      "layers\n",
      "1948\n",
      "inverse\n",
      "depend\n",
      "1943\n",
      "environment\n",
      "0\n",
      "finally\n",
      "analogous\n",
      "Robustness\n",
      "35558945\n",
      "External\n",
      "advantage\n",
      "choice\n",
      "stays\n",
      "1995\n",
      "DBNs\n",
      "Where\n",
      "solves\n",
      "level\n",
      "turns\n",
      "1996\n",
      "solved\n",
      "addressable\n",
      "team\n",
      "generatively\n",
      "Kevin\n",
      "Systems\n",
      "prevent\n",
      "Superpositions\n",
      "maximization\n",
      "discover\n",
      "sign\n",
      "W_\n",
      "slowed\n",
      "cost\n",
      "Bryson\n",
      "pengadaan\n",
      "resurgence\n",
      "adds\n",
      "sequential\n",
      "521\n",
      "international\n",
      "1016\n",
      "course\n",
      "Reeves\n",
      "textstyle\n",
      "303\n",
      "den\n",
      "denoising\n",
      "understanding\n",
      "DSN\n",
      "tangent\n",
      "O\n",
      "splice\n",
      "address\n",
      "teacher\n",
      "change\n",
      "box\n",
      "Computational\n",
      "Dean\n",
      "MC\n",
      "shift\n",
      "vectors\n",
      "commonly\n",
      "usually\n",
      "conveniently\n",
      "navigation\n",
      "tasks\n",
      "useful\n",
      "convolution\n",
      "extra\n",
      "When\n",
      "compare\n",
      "DOD\n",
      "modifying\n",
      "traversing\n",
      "handled\n",
      "sake\n",
      "predictions\n",
      "approach\n",
      "opposed\n",
      "memory\n",
      "selects\n",
      "theoretical\n",
      "today\n",
      "introducing\n",
      "TDSNs\n",
      "Bhadeshia\n",
      "Neural\n",
      "These\n",
      "outputs\n",
      "visual\n",
      "sentences\n",
      "cases\n",
      "valued\n",
      "bits\n",
      "concatenated\n",
      "local\n",
      "facilitating\n",
      "modified\n",
      "cat\n",
      "labeled\n",
      "Minimizing\n",
      "values\n",
      "can\n",
      "following\n",
      "making\n",
      "modifies\n",
      "nearest\n",
      "corrupted\n",
      "figure\n",
      "predict\n",
      "chip\n",
      "decoders\n",
      "agent\n",
      "sample\n",
      "performed\n",
      "allowed\n",
      "Walter\n",
      "Bertsekas\n",
      "regularization\n",
      "redundancy\n",
      "watching\n",
      "1\n",
      "optimal\n",
      "isijinternational\n",
      "parameter\n",
      "inputs\n",
      "designer\n",
      "s_\n",
      "irrational\n",
      "0132733501\n",
      "may\n",
      "max\n",
      "blocks\n",
      "applications\n",
      "produce\n",
      "Wiesel\n",
      "such\n",
      "data\n",
      "38908586\n",
      "MNIST\n",
      "times\n",
      "natural\n",
      "dynamical\n",
      "Sigmoidal\n",
      "Gaussian\n",
      "q\n",
      "cascade\n",
      "annealing\n",
      "so\n",
      "progressively\n",
      "Fukushima\n",
      "representation\n",
      "gesture\n",
      "typical\n",
      "exclusive\n",
      "serving\n",
      "thresholds\n",
      "Jan\n",
      "brain\n",
      "Simon\n",
      "statistical\n",
      "argued\n",
      "still\n",
      "pointer\n",
      "group\n",
      "how\n",
      "decreases\n",
      "forms\n",
      "Wesley\n",
      "offers\n",
      "policy\n",
      "Using\n",
      "main\n",
      "Neuro\n",
      "happened\n",
      "non\n",
      "squares\n",
      "views\n",
      "matches\n",
      "regarding\n",
      "Reinforcement\n",
      "scaling\n",
      "1954\n",
      "TPU\n",
      "1956\n",
      "tails\n",
      "not\n",
      "1959\n",
      "1958\n",
      "maintaining\n",
      "matched\n",
      "term\n",
      "name\n",
      "didn\n",
      "arrows\n",
      "domain\n",
      "weighted\n",
      "significantly\n",
      "Duda\n",
      "ed\n",
      "ANNs\n",
      "challenges\n",
      "menggunakan\n",
      "et\n",
      "jasa\n",
      "disasters\n",
      "Levenberg\n",
      "predefined\n",
      "emerges\n",
      "shown\n",
      "space\n",
      "squared\n",
      "increase\n",
      "attracted\n",
      "seriously\n",
      "exploding\n",
      "rational\n",
      "receiving\n",
      "sensor\n",
      "correct\n",
      "theory\n",
      "G\n",
      "Sometimes\n",
      "mechanisms\n",
      "possibility\n",
      "abdomen\n",
      "Haykin\n",
      "dependencies\n",
      "complicated\n",
      "Correlation\n",
      "Grundlagen\n",
      "card\n",
      "training\n",
      "fixed\n",
      "derivation\n",
      "language\n",
      "transition\n",
      "programming\n",
      "Sign\n",
      "ssRBMs\n",
      "geomorphology\n",
      "first\n",
      "blind\n",
      "xi\n",
      "Tensor\n",
      "spoken\n",
      "variables\n",
      "symbolic\n",
      "Hertz\n",
      "nested\n",
      "simplified\n",
      "fast\n",
      "directly\n",
      "generative\n",
      "methodological\n",
      "summarize\n",
      "size\n",
      "given\n",
      "necessarily\n",
      "categorical\n",
      "structured\n",
      "2\n",
      "x_\n",
      "initialized\n",
      "Such\n",
      "Data\n",
      "gives\n",
      "exploring\n",
      "mining\n",
      "that\n",
      "brains\n",
      "continuous\n",
      "PDF\n",
      "representing\n",
      "than\n",
      "History\n",
      "relative\n",
      "impractical\n",
      "effective\n",
      "require\n",
      "were\n",
      "and\n",
      "addressing\n",
      "dynamically\n",
      "generalization\n",
      "cortexes\n",
      "slab\n",
      "any\n",
      "subsystems\n",
      "computationally\n",
      "DNC\n",
      "efficient\n",
      "answering\n",
      "ideas\n",
      "note\n",
      "take\n",
      "online\n",
      "Gurney\n",
      "performance\n",
      "Hall\n",
      "multiple\n",
      "Unlike\n",
      "normal\n",
      "MLP\n",
      "printed\n",
      "successive\n",
      "Markov\n",
      "Furthermore\n",
      "operate\n",
      "especially\n",
      "considered\n",
      "average\n",
      "Convergent\n",
      "Netze\n",
      "cortex\n",
      "typically\n",
      "drastically\n",
      "formal\n",
      "Cybenko\n",
      "Research\n",
      "discovered\n",
      "Kordylewski\n",
      "threshold\n",
      "slow\n",
      "proportion\n",
      "enough\n",
      "only\n",
      "explicitly\n",
      "black\n",
      "ranking\n",
      "Integrating\n",
      "H\n",
      "expectation\n",
      "Large\n",
      "cannot\n",
      "Ciresan\n",
      "invariant\n",
      "Similar\n",
      "synapse\n",
      "resource\n",
      "summary\n",
      "cochlea\n",
      "predicted\n",
      "mapped\n",
      "920\n",
      "4976\n",
      "where\n",
      "vision\n",
      "kernel\n",
      "connections\n",
      "Murray\n",
      "Target\n",
      "That\n",
      "ways\n",
      "review\n",
      "hybrid\n",
      "label\n",
      "3\n",
      "Hierarchical\n",
      "between\n",
      "affecting\n",
      "geometric\n",
      "Natural\n",
      "benchmarks\n",
      "jl\n",
      "Backpropagation\n",
      "Advocates\n",
      "Each\n",
      "rapidly\n",
      "recall\n",
      "dates\n",
      "many\n",
      "region\n",
      "auditory\n",
      "according\n",
      "Generalization\n",
      "called\n",
      "enabling\n",
      "propagation\n",
      "s\n",
      "aura\n",
      "WWN\n",
      "expression\n",
      "Tutorial\n",
      "nearby\n",
      "among\n",
      "filtering\n",
      "cancer\n",
      "robotics\n",
      "pop\n",
      "sampling\n",
      "64\n",
      "learning\n",
      "associated\n",
      "Numerous\n",
      "noisy\n",
      "considering\n",
      "tuning\n",
      "Turing\n",
      "locally\n",
      "Multilayer\n",
      "combined\n",
      "52377690\n",
      "Identity\n",
      "00178\n",
      "direction\n",
      "external\n",
      "declaration\n",
      "Vincent\n",
      "those\n",
      "case\n",
      "stacked\n",
      "structures\n",
      "these\n",
      "Systemen\n",
      "engineering\n",
      "Implicit\n",
      "intimately\n",
      "ongoing\n",
      "coupled\n",
      "characteristics\n",
      "MKM\n",
      "bias\n",
      "Useless\n",
      "Moewes\n",
      "technology\n",
      "binary\n",
      "different\n",
      "tour\n",
      "same\n",
      "speech\n",
      "Variants\n",
      "document\n",
      "events\n",
      "autonomously\n",
      "extended\n",
      "Signal\n",
      "Modules\n",
      "arose\n",
      "changing\n",
      "invariance\n",
      "largely\n",
      "minimize\n",
      "Kolmogorov\n",
      "It\n",
      "objection\n",
      "without\n",
      "solve\n",
      "components\n",
      "In\n",
      "masks\n",
      "model\n",
      "researchers\n",
      "If\n",
      "gates\n",
      "minima\n",
      "being\n",
      "generally\n",
      "actions\n",
      "NAS\n",
      "gated\n",
      "differentiation\n",
      "speed\n",
      "feedforward\n",
      "heuristic\n",
      "renewed\n",
      "mother\n",
      "trigger\n",
      "seems\n",
      "improvement\n",
      "Applications\n",
      "samples\n",
      "0304\n",
      "momentum\n",
      "real\n",
      "psi\n",
      "aspects\n",
      "around\n",
      "Rosenblatt\n",
      "Unsupervised\n",
      "rules\n",
      "Many\n",
      "decomposed\n",
      "early\n",
      "inhibition\n",
      "grid\n",
      "using\n",
      "particle\n",
      "Palmer\n",
      "reduces\n",
      "serves\n",
      "nu\n",
      "t\n",
      "neuronal\n",
      "always\n",
      "output\n",
      "Beale\n",
      "reduced\n",
      "Recognition\n",
      "grouping\n",
      "DBMs\n",
      "alternated\n",
      "conditional\n",
      "10\n",
      "Geoffrey\n",
      "specified\n",
      "images\n",
      "International\n",
      "organizing\n",
      "matching\n",
      "AD\n",
      "provided\n",
      "memories\n",
      "Earlier\n",
      "recorded\n",
      "critical\n",
      "decomposition\n",
      "provides\n",
      "mathcal\n",
      "semantically\n",
      "Projects\n",
      "Extreme\n",
      "accessing\n",
      "scientific\n",
      "power\n",
      "equivalent\n",
      "fitness\n",
      "Nostrand\n",
      "o_\n",
      "GPGPUs\n",
      "Ripley\n",
      "Wasserman\n",
      "found\n",
      "refers\n",
      "_\n",
      "on\n",
      "Tasks\n",
      "central\n",
      "of\n",
      "practical\n",
      "supervised\n",
      "neighbor\n",
      "acyclic\n",
      "or\n",
      "Capacity\n",
      "No\n",
      "unbounded\n",
      "image\n",
      "numerically\n",
      "Ng\n",
      "Stork\n",
      "imitates\n",
      "operator\n",
      "Baidu\n",
      "log\n",
      "NN\n",
      "area\n",
      "strictly\n",
      "cats\n",
      "µ\n",
      "low\n",
      "series\n",
      "c_\n",
      "complete\n",
      "J\n",
      "tailored\n",
      "posterior\n",
      "Ivakhnenko\n",
      "N3\n",
      "with\n",
      "pull\n",
      "datasets\n",
      "applying\n",
      "multiplications\n",
      "connect\n",
      "strongly\n",
      "ad\n",
      "videos\n",
      "certain\n",
      "combining\n",
      "al\n",
      "deep\n",
      "general\n",
      "How\n",
      "as\n",
      "senses\n",
      "at\n",
      "formulation\n",
      "Mathematics\n",
      "gradients\n",
      "New\n",
      "fill\n",
      "Computer\n",
      "storage\n",
      "As\n",
      "multiclass\n",
      "2001\n",
      "valid\n",
      "5\n",
      "spatial\n",
      "mathematics\n",
      "you\n",
      "really\n",
      "a_\n",
      "At\n",
      "poor\n",
      "vocabulary\n",
      "separate\n",
      "ψ\n",
      "whiskers\n",
      "m\n",
      "Practical\n",
      "attentional\n",
      "important\n",
      "recognise\n",
      "CNN\n",
      "building\n",
      "mask\n",
      "Hardware\n",
      "Brain\n",
      "u\n",
      "parallelism\n",
      "original\n",
      "Analog\n",
      "represent\n",
      "all\n",
      "semantic\n",
      "consider\n",
      "lack\n",
      "Farley\n",
      "LSTM\n",
      "Convolutional\n",
      "batches\n",
      "to\n",
      "stochastic\n",
      "nodes\n",
      "Self\n",
      "Training\n",
      "Aplikasi\n",
      "straightforward\n",
      "far\n",
      "27145760\n",
      "fall\n",
      "difference\n",
      "heaven\n",
      "potentiation\n",
      "0471049638\n",
      "applicable\n",
      "large\n",
      "adjust\n",
      "small\n",
      "biological\n",
      "rate\n",
      "design\n",
      "pass\n",
      "further\n",
      "attributable\n",
      "bilinear\n",
      "what\n",
      "nonlinear\n",
      "sub\n",
      "sum\n",
      "brief\n",
      "version\n",
      "Compound\n",
      "activations\n",
      "learned\n",
      "method\n",
      "hasn\n",
      "full\n",
      "K\n",
      "component\n",
      "behaviour\n",
      "algoritma\n",
      "dimensionality\n",
      "table\n",
      "search\n",
      "Clark\n",
      "inspired\n",
      "losses\n",
      "allows\n",
      "experience\n",
      "prior\n",
      "amount\n",
      "social\n",
      "action\n",
      "via\n",
      "followed\n",
      "ReLU\n",
      "Agency\n",
      "analyzing\n",
      "trained\n",
      "perceptron\n",
      "detecting\n",
      "select\n",
      "conventional\n",
      "eye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminative\n",
      "852\n",
      "distinct\n",
      "contains\n",
      "determined\n",
      "quasi\n",
      "automata\n",
      "η\n",
      "taken\n",
      "Neuroscience\n",
      "entails\n",
      "more\n",
      "Roger\n",
      "varying\n",
      "known\n",
      "undirected\n",
      "Neumann\n",
      "science\n",
      "equation\n",
      "33101074\n",
      "resources\n",
      "evolved\n",
      "learn\n",
      "Minsky\n",
      "Conference\n",
      "Different\n",
      "stacking\n",
      "share\n",
      "states\n",
      "minimum\n",
      "numbers\n",
      "sense\n",
      "phrase\n",
      "Neuronaler\n",
      "information\n",
      "needs\n",
      "goal\n",
      "Siegelmann\n",
      "rather\n",
      "acts\n",
      "maps\n",
      "Electron\n",
      "RBMs\n",
      "circuit\n",
      "Schneider\n",
      "derived\n",
      "mapping\n",
      "reflect\n",
      "connectivity\n",
      "tries\n",
      "preprocessing\n",
      "lighting\n",
      "response\n",
      "a\n",
      "sourcebook\n",
      "short\n",
      "Deep\n",
      "f_\n",
      "fundamental\n",
      "playing\n",
      "What\n",
      "help\n",
      "reservoir\n",
      "hierarchy\n",
      "developed\n",
      "trade\n",
      "radar\n",
      "through\n",
      "filters\n",
      "1499\n",
      "its\n",
      "20\n",
      "McCulloch\n",
      "translation\n",
      "late\n",
      "detected\n",
      "90178\n",
      "systems\n",
      "travelling\n",
      "might\n",
      "deformation\n",
      "finer\n",
      "good\n",
      "motivated\n",
      "propose\n",
      "L\n",
      "Overly\n",
      "2D\n",
      "framework\n",
      "wise\n",
      "compound\n",
      "association\n",
      "Semantic\n",
      "Elliot\n",
      "fully\n",
      "Newton\n",
      "Connections\n",
      "y_\n",
      "inherent\n",
      "characterized\n",
      "referred\n",
      "weight\n",
      "HDP\n",
      "energy\n",
      "reduce\n",
      "idea\n",
      "wires\n",
      "fewer\n",
      "quantum\n",
      "operation\n",
      "beyond\n",
      "event\n",
      "twists\n",
      "More\n",
      "p\n",
      "research\n",
      "7\n",
      "induced\n",
      "EM\n",
      "belief\n",
      "localization\n",
      "favored\n",
      "confidence\n",
      "0442004613\n",
      "difficulty\n",
      "base\n",
      "Architecture\n",
      "members\n",
      "teach\n",
      "generate\n",
      "Researchers\n",
      "definition\n",
      "pairs\n",
      "computers\n",
      "introduction\n",
      "exponentially\n",
      "w\n",
      "twenty\n",
      "corrupting\n",
      "feed\n",
      "major\n",
      "probability\n",
      "encoding\n",
      "relate\n",
      "number\n",
      "linking\n",
      "done\n",
      "979\n",
      "passes\n",
      "differ\n",
      "heads\n",
      "Models\n",
      "leading\n",
      "interact\n",
      "least\n",
      "978\n",
      "swarm\n",
      "0471056693\n",
      "scheme\n",
      "too\n",
      "boldsymbol\n",
      "Language\n",
      "behind\n",
      "prediction\n",
      "part\n",
      "DPCNs\n",
      "Problem\n",
      "classifiers\n",
      "kind\n",
      "b\n",
      "determines\n",
      "Often\n",
      "Neurons\n",
      "motivation\n",
      "modeled\n",
      "Werbos\n",
      "roughly\n",
      "randomly\n",
      "neocognitron\n",
      "conjugate\n",
      "DMOZ\n",
      "robustly\n",
      "zero\n",
      "depending\n",
      "self\n",
      "Sontag\n",
      "onset\n",
      "also\n",
      "empirically\n",
      "internal\n",
      "generalized\n",
      "finding\n",
      "UCL\n",
      "With\n",
      "experienced\n",
      "multilingual\n",
      "M\n",
      "most\n",
      "RBM\n",
      "sponsored\n",
      "significant\n",
      "nothing\n",
      "The\n",
      "infrastructures\n",
      "probabilistic\n",
      "intervenes\n",
      "deviations\n",
      "Google\n",
      "unsupervised\n",
      "popularity\n",
      "traditional\n",
      "exp\n",
      "Vieweg\n",
      "hyper\n",
      "particularly\n",
      "Patent\n",
      "converge\n",
      "Signals\n",
      "Thirdly\n",
      "Marquardt\n",
      "registers\n",
      "relation\n",
      "hyped\n",
      "fine\n",
      "find\n",
      "backtracking\n",
      "cell\n",
      "simulating\n",
      "parameters\n",
      "bisnis\n",
      "Similarly\n",
      "distributed\n",
      "Stacks\n",
      "Traffic\n",
      "convoluted\n",
      "captures\n",
      "Based\n",
      "Masters\n",
      "his\n",
      "notation\n",
      "dependent\n",
      "express\n",
      "While\n",
      "devising\n",
      "during\n",
      "F33615\n",
      "restart\n",
      "Features\n",
      "remove\n",
      "noising\n",
      "Held\n",
      "common\n",
      "logistic\n",
      "x\n",
      "Networks\n",
      "set\n",
      "Graves\n",
      "For\n",
      "achieved\n",
      "intelligence\n",
      "Schuppen\n",
      "314\n",
      "achieves\n",
      "see\n",
      "individual\n",
      "are\n",
      "close\n",
      "Hinton\n",
      "analog\n",
      "Bridgman\n",
      "learns\n",
      "expert\n",
      "Boltzmann\n",
      "smallest\n",
      "various\n",
      "corruption\n",
      "available\n",
      "sparsely\n",
      "attention\n",
      "scalability\n",
      "Limiting\n",
      "vanishing\n",
      "interface\n",
      "interfaced\n",
      "Linnainmaa\n",
      "both\n",
      "c\n",
      "paradigms\n",
      "improved\n",
      "license\n",
      "ANN\n",
      "imparts\n",
      "sensitive\n",
      "embodiments\n",
      "became\n",
      "context\n",
      "Yes\n",
      "Hart\n",
      "whole\n",
      "Wan\n",
      "Ultimately\n",
      "consume\n",
      "point\n",
      "simple\n",
      "p_\n",
      "Nobel\n",
      "dimensional\n",
      "unfolded\n",
      "simply\n",
      "kernels\n",
      "pp\n",
      "described\n",
      "transformations\n",
      "create\n",
      "Processing\n",
      "due\n",
      "strategy\n",
      "Most\n",
      "reduction\n",
      "California\n",
      "Although\n",
      "fire\n",
      "transferring\n",
      "precision\n",
      "DSNs\n",
      "N\n",
      "vaguely\n",
      "determination\n",
      "incoming\n",
      "assigning\n",
      "Software\n",
      "966\n",
      "handling\n",
      "fur\n",
      "Reservoir\n",
      "Classification\n",
      "raw\n",
      "expanded\n",
      "batch\n",
      "Approximation\n",
      "while\n",
      "optimization\n",
      "Dong\n",
      "error\n",
      "engineers\n",
      "larger\n",
      "century\n",
      "Temporal\n",
      "cleaned\n",
      "encountered\n",
      "neurons\n",
      "seen\n",
      "rightarrow\n",
      "Behnke\n",
      "belong\n",
      "shorten\n",
      "read\n",
      "reconstructed\n",
      "widely\n",
      "9\n",
      "composition\n",
      "higher\n",
      "used\n",
      "unlabeled\n",
      "comprehensive\n",
      "generalizes\n",
      "domains\n",
      "levels\n",
      "uses\n",
      "purpose\n",
      "aggregate\n",
      "robust\n",
      "ssRBM\n",
      "stack\n",
      "lower\n",
      "task\n",
      "Inference\n",
      "database\n",
      "Almost\n",
      "studies\n",
      "analysis\n",
      "Examples\n",
      "y\n",
      "traffic\n",
      "chemistry\n",
      "parametric\n",
      "grossly\n",
      "pillory\n",
      "unseen\n",
      "Ridder\n",
      "competitive\n",
      "Nanodevices\n",
      "IJCNN\n",
      "shape\n",
      "world\n",
      "Taken\n",
      "inference\n",
      "alternative\n",
      "alignment\n",
      "Theory\n",
      "extracted\n",
      "guaranteed\n",
      "signals\n",
      "source\n",
      "Christopher\n",
      "location\n",
      "theorem\n",
      "input\n",
      "transformation\n",
      "apnea\n",
      "valueless\n",
      "uncorrupted\n",
      "couple\n",
      "unlimited\n",
      "deepening\n",
      "game\n",
      "bit\n",
      "weights\n",
      "helpful\n",
      "sorting\n",
      "d\n",
      "Computing\n",
      "signal\n",
      "yields\n",
      "Learning\n",
      "popular\n",
      "mode\n",
      "mathematical\n",
      "methods\n",
      "discrete\n",
      "Pattern\n",
      "some\n",
      "back\n",
      "added\n",
      "examples\n",
      "Curlie\n",
      "CMAC\n",
      "delivered\n",
      "gradually\n",
      "scale\n",
      "affects\n",
      "decision\n",
      "Wiley\n",
      "novelty\n",
      "prop\n",
      "competitions\n",
      "connecting\n",
      "preprocessors\n",
      "innovation\n",
      "either\n",
      "be\n",
      "run\n",
      "processing\n",
      "bi\n",
      "Microscopy\n",
      "David\n",
      "Cascade\n",
      "step\n",
      "Goldfarb\n",
      "Typically\n",
      "by\n",
      "von\n",
      "integers\n",
      "anything\n",
      "stationary\n",
      "simulation\n",
      "range\n",
      "regular\n",
      "LAMSTAR\n",
      "experiences\n",
      "block\n",
      "flying\n",
      "computational\n",
      "colorectal\n",
      "into\n",
      "within\n",
      "Their\n",
      "Documents\n",
      "clustering\n",
      "criticisms\n",
      "statistics\n",
      "spam\n",
      "multilayer\n",
      "governed\n",
      "question\n",
      "long\n",
      "Every\n",
      "forward\n",
      "Fuzzy\n",
      "analyze\n",
      "arise\n",
      "Connectionist\n",
      "retina\n",
      "doi\n",
      "link\n",
      "repeatedly\n",
      "considerable\n",
      "deployed\n",
      "directed\n",
      "circuits\n",
      "characteristic\n",
      "up\n",
      "differentiable\n",
      "Pascal\n",
      "continuously\n",
      "z\n",
      "similar\n",
      "calculated\n",
      "2355\n",
      "constant\n",
      "defined\n",
      "Dynamic\n",
      "Cross\n",
      "To\n",
      "single\n",
      "diverse\n",
      "Arguments\n",
      "Memory\n",
      "defines\n",
      "encoders\n",
      "amounts\n",
      "priors\n",
      "F\n",
      "DNNs\n",
      "application\n",
      "priori\n",
      "coded\n",
      "Hub5\n",
      "Polak\n",
      "θ\n",
      "elements\n",
      "neurodynamic\n",
      "generates\n",
      "benchmark\n",
      "problems\n",
      "polynomials\n",
      "generated\n",
      "allowing\n",
      "depicting\n",
      "structure\n",
      "ago\n",
      "independently\n",
      "e\n",
      "algorithm\n",
      "required\n",
      "An\n",
      "2002\n",
      "2003\n",
      "depth\n",
      "implied\n",
      "2006\n",
      "2007\n",
      "2004\n",
      "2008\n",
      "2009\n",
      "requires\n",
      "having\n",
      "partial\n",
      "Ribiére\n",
      "broaden\n",
      "laziness\n",
      "results\n",
      "illustrated\n",
      "query\n",
      "CPU\n",
      "issues\n",
      "compose\n",
      "g_\n",
      "concerned\n",
      "deterministic\n",
      "ARPA\n",
      "factoring\n",
      "Encoder\n",
      "languages\n",
      "helps\n",
      "stable\n",
      "cluttered\n",
      "include\n",
      "ν\n",
      "sent\n",
      "labels\n",
      "Holland\n",
      "implicitly\n",
      "P\n",
      "bounding\n",
      "categories\n",
      "entire\n",
      "magic\n",
      "uncovering\n",
      "notes\n",
      "Concise\n",
      "Competition\n",
      "try\n",
      "Defense\n",
      "neuromorphic\n",
      "noted\n",
      "Bibliography\n",
      "Long\n",
      "Mathematically\n",
      "fold\n",
      "State\n",
      "video\n",
      "barang\n",
      "manipulating\n",
      "dynamics\n",
      "3D\n",
      "opaque\n",
      "giving\n",
      "Sensor\n",
      "9783528252656\n",
      "networks\n",
      "access\n",
      "consistently\n",
      "secant\n",
      "flowing\n",
      "Handels\n",
      "delving\n",
      "led\n",
      "degree\n",
      "respectively\n",
      "jointly\n",
      "DPCN\n",
      "leq\n",
      "objects\n",
      "focused\n",
      "separation\n",
      "others\n",
      "implicit\n",
      "HMMs\n",
      "39\n",
      "360\n",
      "receive\n",
      "involved\n",
      "adjusts\n",
      "Back\n",
      "35\n",
      "resulting\n",
      "approximator\n",
      "gene\n",
      "makes\n",
      "displaystyle\n",
      "composed\n",
      "formulated\n",
      "addresses\n",
      "claim\n",
      "win\n",
      "331\n",
      "scaled\n",
      "addressed\n",
      "boolean\n",
      "formulates\n",
      "motor\n",
      "analyses\n",
      "relaying\n",
      "use\n",
      "from\n",
      "next\n",
      "few\n",
      "depicted\n",
      "Dewdney\n",
      "vehicle\n",
      "Steinbrecher\n",
      "MDP\n",
      "simpler\n",
      "convolutional\n",
      "formally\n",
      "started\n",
      "mismatch\n",
      "Convergence\n",
      "train\n",
      "Supervised\n",
      "disabling\n",
      "1980s\n",
      "crosses\n",
      "f\n",
      "this\n",
      "challenge\n",
      "Unfortunately\n",
      "reproduce\n",
      "NTM\n",
      "columns\n",
      "Secondly\n",
      "ALU\n",
      "Technology\n",
      "proof\n",
      "control\n",
      "links\n",
      "do\n",
      "process\n",
      "high\n",
      "effectively\n",
      "assumptions\n",
      "something\n",
      "serial\n",
      "relied\n",
      "overfitting\n",
      "regions\n",
      "located\n",
      "animal\n",
      "frac\n",
      "collection\n",
      "41347061\n",
      "prostate\n",
      "efficiently\n",
      "realized\n",
      "lines\n",
      "correspond\n",
      "One\n",
      "allow\n",
      "bipartite\n",
      "sigmoid\n",
      "areas\n",
      "Smith\n",
      "interpreted\n",
      "131\n",
      "including\n",
      "graph\n",
      "reconstruct\n",
      "mentioned\n",
      "bunch\n",
      "superior\n",
      "Scientific\n",
      "chosen\n",
      "temporal\n",
      "lm\n",
      "2015\n",
      "2014\n",
      "retrieval\n",
      "defining\n",
      "2010\n",
      "2013\n",
      "2012\n",
      "designs\n",
      "greater\n",
      "articulation\n",
      "Gabor\n",
      "auto\n",
      "dan\n",
      "material\n",
      "Two\n",
      "dock\n",
      "transparent\n",
      "successor\n",
      "Layer\n",
      "sufficiently\n",
      "softmax\n",
      "reproducing\n",
      "From\n",
      "determine\n",
      "map\n",
      "related\n",
      "constitute\n",
      "frequency\n",
      "static\n",
      "variety\n",
      "measure\n",
      "our\n",
      "Structures\n",
      "87\n",
      "special\n",
      "out\n",
      "maximizes\n",
      "matrix\n",
      "integrates\n",
      "performs\n",
      "maximized\n",
      "adaptive\n",
      "32179420\n",
      "interactions\n",
      "This\n",
      "hyperparameters\n",
      "greedy\n",
      "approaches\n",
      "tied\n",
      "van\n",
      "backwards\n",
      "g\n",
      "determining\n",
      "could\n",
      "feasible\n",
      "explored\n",
      "quadratically\n",
      "facilitate\n",
      "designed\n",
      "powerful\n",
      "improvements\n",
      "representations\n",
      "Rochester\n",
      "quality\n",
      "Theoretical\n",
      "management\n",
      "hyperbolic\n",
      "unknown\n",
      "system\n",
      "adopted\n",
      "their\n",
      "final\n",
      "paved\n",
      "accompany\n",
      "shallow\n",
      "R\n",
      "simulate\n",
      "detection\n",
      "colleagues\n",
      "pointers\n",
      "References\n",
      "Fletcher\n",
      "Peter\n",
      "Information\n",
      "ISBI\n",
      "ISBN\n",
      "Richard\n",
      "robot\n",
      "Machine\n",
      "Other\n",
      "have\n",
      "need\n",
      "element\n",
      "viewed\n",
      "27429729\n",
      "documents\n",
      "min\n",
      "marginalizing\n",
      "able\n",
      "accelerated\n",
      "mechanism\n",
      "mix\n",
      "3975\n",
      "best\n",
      "which\n",
      "Science\n",
      "Bayesian\n",
      "techniques\n",
      "mit\n",
      "accuracy\n",
      "unless\n",
      "who\n",
      "eight\n",
      "Contract\n",
      "class\n",
      "Graupe\n",
      "plasticity\n",
      "Some\n",
      "face\n",
      "normally\n",
      "Bishop\n",
      "Krogh\n",
      "text\n",
      "purely\n",
      "Document\n",
      "trivial\n",
      "principal\n",
      "textual\n",
      "based\n",
      "knowledge\n",
      "CNNs\n",
      "produces\n",
      "won\n",
      "trainability\n",
      "York\n",
      "molecules\n",
      "partially\n",
      "thousands\n",
      "achieve\n",
      "1883157005\n",
      "handle\n",
      "RNNs\n",
      "means\n",
      "overall\n",
      "q_\n",
      "joint\n",
      "cerebellar\n",
      "words\n",
      "GPU\n",
      "chips\n",
      "Once\n",
      "processes\n",
      "Because\n",
      "Matthias\n",
      "upper\n",
      "h\n",
      "tuned\n",
      "optimally\n",
      "processed\n",
      "contain\n",
      "cycles\n",
      "view\n",
      "predictive\n",
      "requirement\n",
      "constructing\n",
      "exists\n",
      "variations\n",
      "C\n",
      "module\n",
      "operates\n",
      "computes\n",
      "computer\n",
      "Various\n",
      "enhanced\n",
      "Lapa\n",
      "Borgelt\n",
      "statistically\n",
      "closer\n",
      "affine\n",
      "pattern\n",
      "PC\n",
      "state\n",
      "identification\n",
      "routing\n",
      "closed\n",
      "Preliminary\n",
      "theta\n",
      "textbook\n",
      "ability\n",
      "opening\n",
      "notion\n",
      "Differentiable\n",
      "efficiency\n",
      "S\n",
      "hypothesis\n",
      "key\n",
      "problem\n",
      "hydrology\n",
      "RNN\n",
      "taking\n",
      "equal\n",
      "etc\n",
      "eta\n",
      "forall\n",
      "estimation\n",
      "otherwise\n",
      "captioning\n",
      "Timothy\n",
      "adjusted\n",
      "relevant\n",
      "invasive\n",
      "Artificial\n",
      "9780521642989\n",
      "distinguish\n",
      "sequences\n",
      "respect\n",
      "electrocardiogram\n",
      "addition\n",
      "trajectory\n",
      "recognizers\n",
      "slowly\n",
      "Switchboard\n",
      "ImageNet\n",
      "topology\n",
      "define\n",
      "arises\n",
      "corresponding\n",
      "neighbour\n",
      "controller\n",
      "OCLC\n",
      "derivative\n",
      "last\n",
      "an\n",
      "Deng\n",
      "multi\n",
      "novel\n",
      "unlike\n",
      "2011\n",
      "Number\n",
      "value\n",
      "choices\n",
      "will\n",
      "frameworks\n",
      "reliability\n",
      "handwriting\n",
      "Queens\n",
      "ill\n",
      "layer\n",
      "manually\n",
      "almost\n",
      "neuron\n",
      "thus\n",
      "pruned\n",
      "surface\n",
      "hardware\n",
      "vs\n",
      "claimed\n",
      "regression\n",
      "finance\n",
      "capture\n",
      "cross\n",
      "parts\n",
      "units\n",
      "Reinhold\n",
      "1857286731\n",
      "finite\n",
      "propagate\n",
      "infer\n",
      "Types\n",
      "difficult\n",
      "Handling\n",
      "logic\n",
      "upon\n",
      "functions\n",
      "exceeds\n",
      "Broyden\n",
      "architectures\n",
      "infinite\n",
      "frequently\n",
      "Order\n",
      "off\n",
      "neural\n",
      "i\n",
      "contest\n",
      "well\n",
      "thought\n",
      "patterns\n",
      "backpropagation\n",
      "sets\n",
      "firstly\n",
      "position\n",
      "muscle\n",
      "less\n",
      "compel\n",
      "accurate\n",
      "stored\n",
      "Segmentation\n",
      "density\n",
      "YouTube\n",
      "capabilities\n",
      "By\n",
      "increased\n",
      "proses\n",
      "corresponds\n",
      "increases\n",
      "T\n",
      "Components\n",
      "variants\n",
      "loss\n",
      "Evolutionary\n",
      "necessary\n",
      "like\n",
      "lost\n",
      "extremely\n",
      "controllers\n",
      "Anders\n",
      "become\n",
      "works\n",
      "because\n",
      "sequence\n",
      "EET\n",
      "Excel\n",
      "convex\n",
      "recognition\n",
      "parallelization\n",
      "broad\n",
      "avoid\n",
      "Lebiere\n",
      "miner\n",
      "However\n",
      "instantaneous\n",
      "referential\n",
      "does\n",
      "assuming\n",
      "capability\n",
      "demonstrated\n",
      "ξ\n",
      "hinder\n",
      "biology\n",
      "noise\n",
      "selecting\n",
      "künstlicher\n",
      "Materials\n",
      "although\n",
      "offset\n",
      "approximating\n",
      "stage\n",
      "about\n",
      "actual\n",
      "extension\n",
      "freedom\n",
      "certainty\n",
      "dependence\n",
      "introduced\n",
      "Pointer\n",
      "software\n",
      "discretization\n",
      "own\n",
      "76538146\n",
      "functional\n",
      "dataset\n",
      "lung\n",
      "additions\n",
      "fraud\n",
      "Network\n",
      "1986\n",
      "1982\n",
      "additional\n",
      "Lawrence\n",
      "much\n",
      "inspiration\n",
      "naturally\n",
      "function\n",
      "aircraft\n",
      "directing\n",
      "but\n",
      "hierarchical\n",
      "gain\n",
      "automated\n",
      "convergence\n",
      "he\n",
      "count\n",
      "made\n",
      "compute\n",
      "h_\n",
      "wish\n",
      "cells\n",
      "j\n",
      "smooth\n",
      "reinforcement\n",
      "placed\n",
      "steepest\n",
      "demonstrate\n",
      "distribution\n",
      "recognize\n",
      "universal\n",
      "implement\n",
      "periods\n",
      "MSE\n",
      "proceeds\n",
      "Function\n",
      "mutual\n",
      "49\n",
      "salesman\n",
      "virtual\n",
      "CC\n",
      "other\n",
      "Improving\n",
      "mass\n",
      "Robotics\n",
      "kinds\n",
      "covariance\n",
      "U\n",
      "modelling\n",
      "Neuronal\n",
      "fundamentally\n",
      "Contests\n",
      "factors\n",
      "Thus\n",
      "rule\n",
      "diagnosis\n",
      "GPUs\n",
      "validation\n",
      "augmented\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#counting words\n",
    "# \\w+ matches Any word character (letter, number, underscore)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(text)\n",
    "#print type(tokens) \n",
    "#print tokens\n",
    "\n",
    "#finding vocabulary\n",
    "#removing numbers, but keep words that contain numbers, e.g. Area51 \n",
    "def uniq(inlist): \n",
    "    return set(inlist)\n",
    "\n",
    "vocabulary=uniq(tokens)\n",
    "\n",
    "print \"Size of vocabulary: \",len(vocabulary), \"words.\"\n",
    "\n",
    "print \"\\nVocabulary contains: \"\n",
    "print \"***********\"\n",
    "for i in vocabulary:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Calculating Sentences</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences:  549\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize_list = sent_tokenize(text, \"english\")\n",
    "\n",
    "print \"Total number of sentences: \", len(sent_tokenize_list)\n",
    "\n",
    "#debugging purposes\n",
    "#print \"*****************************************************************\"\n",
    "#for sentence in sent_tokenize_list:\n",
    "#    print \"Sentence:\" + sentence + \"\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Calculating Lexical Diversity</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity:  0.225669319826\n"
     ]
    }
   ],
   "source": [
    "#Lexical diversity:unique words divided by the total number of words (tokens). \n",
    "LD=len(vocabulary)/ float(len(tokens))\n",
    "print \"Lexical Diversity: \", LD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Part of Speech Tagging</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common pos tags:\n",
      "*********************\n",
      "NOUN\n",
      "VERB\n",
      "ADJ\n",
      "ADP\n",
      "DET\n"
     ]
    }
   ],
   "source": [
    "tags = nltk.pos_tag(tokens, lang=\"eng\", tagset=\"universal\")\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tags)\n",
    "\n",
    "#5 most common pos tags\n",
    "print \"Most Common pos tags:\"\n",
    "print \"*********************\"\n",
    "for i in tag_fd.most_common(5):\n",
    "    print i[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Most Common Unigrams</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Unigrams(words):\n",
      "****************************\n",
      "displaystyle\n",
      "neural\n",
      "networks\n",
      "learning\n",
      "network\n",
      "function\n",
      "textstyle\n",
      "deep\n",
      "model\n",
      "input\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Fetching stopwords\n",
    "ignoredWords=set(stopwords.words(\"english\"))\n",
    "\n",
    "#converting words to lowercase, to avoid duplicates\n",
    "textWords=[w.lower() for w in tokens]\n",
    "\n",
    "#Creating a list of tokens, where all words with less than 3 characters are removed\n",
    "#in addition to all stopwords being removed\n",
    "textWordsNoStopWords=[w for w in textWords if len(w)>3 and w not in ignoredWords]\n",
    "\n",
    "#calculating Unigrams\n",
    "unigrams = ngrams(textWordsNoStopWords,1)\n",
    "fd =nltk.FreqDist(unigrams)\n",
    "\n",
    "print \"Most Common Unigrams(words):\"\n",
    "print \"****************************\"\n",
    "for i in fd.most_common(10):\n",
    "    print i[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Most Common Bigrams</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Bigrams(set of words):\n",
      "**********************************\n",
      "neural + networks\n",
      "displaystyle + textstyle\n",
      "neural + network\n",
      "cost + function\n",
      "boldsymbol + boldsymbol\n",
      "deep + learning\n",
      "displaystyle + boldsymbol\n",
      "pattern + recognition\n",
      "function + displaystyle\n",
      "machine + learning\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "#finding 10 more common bigrams\n",
    "finder=BigramCollocationFinder.from_words(textWordsNoStopWords)\n",
    "finder.nbest(BigramAssocMeasures.likelihood_ratio,10)\n",
    "\n",
    "print \"Most Common Bigrams(set of words):\"\n",
    "print \"**********************************\"\n",
    "for i in finder.ngram_fd.most_common(10):\n",
    "    print i[0][0], \"+\" , i[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"#9370DB\">Counting Nouns in page</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns appear:  4361  times in the document\n"
     ]
    }
   ],
   "source": [
    "print \"Nouns appear: \", tag_fd.get(\"NOUN\"), \" times in the document\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
